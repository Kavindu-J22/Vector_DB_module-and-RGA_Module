{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vector-db-title"
      },
      "source": [
        "# 🗄️ Vector Database Module - Google Colab\n",
        "\n",
        "This notebook runs **ONLY the Vector Database Module** to process and store legal documents.\n",
        "\n",
        "## 📋 What this does:\n",
        "- Processes Sri Lankan legal documents (Acts, Cases)\n",
        "- Creates embeddings using Legal-BERT/Sentence-BERT\n",
        "- Stores in Pinecone vector database\n",
        "- Chunks documents with proper sequence numbers\n",
        "- Supports multilingual content (Sinhala, Tamil, English)\n",
        "\n",
        "## 🔑 Requirements:\n",
        "- Pinecone API key and environment\n",
        "- Legal documents in the project folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive-vector"
      },
      "outputs": [],
      "source": [
        "# 🔗 Step 1: Mount Google Drive and Setup\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "print(\"📁 Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"✅ Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-vector-packages"
      },
      "outputs": [],
      "source": [
        "# 📦 Step 2: Install Vector DB Specific Packages\n",
        "print(\"📦 Installing Vector Database packages...\")\n",
        "\n",
        "!pip install -q pinecone-client\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q transformers\n",
        "!pip install -q torch\n",
        "!pip install -q numpy pandas\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q nltk spacy\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q tqdm\n",
        "!pip install -q langdetect\n",
        "\n",
        "print(\"✅ Vector Database packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract-vector-project"
      },
      "outputs": [],
      "source": [
        "# 📂 Step 3: Extract Vector DB Module\n",
        "# 🔧 CHANGE THIS PATH to your uploaded zip file location\n",
        "ZIP_PATH = '/content/drive/MyDrive/Vector_DB_module and RGA_Module.zip'\n",
        "\n",
        "print(f\"📂 Extracting Vector DB module from: {ZIP_PATH}\")\n",
        "\n",
        "try:\n",
        "    # Extract the project\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/')\n",
        "    \n",
        "    # Change to Vector DB directory\n",
        "    vector_db_dir = '/content/Vector_DB_module and RGA_Module/Vector_DB_module'\n",
        "    os.chdir(vector_db_dir)\n",
        "    \n",
        "    # Add to Python path\n",
        "    sys.path.append('/content/Vector_DB_module and RGA_Module')\n",
        "    sys.path.append(vector_db_dir)\n",
        "    \n",
        "    print(\"✅ Vector DB module extracted successfully!\")\n",
        "    print(\"📁 Vector DB module contents:\")\n",
        "    !ls -la\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Zip file not found! Please check the ZIP_PATH variable.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error extracting project: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-vector-env"
      },
      "outputs": [],
      "source": [
        "# 🔑 Step 4: Setup Vector DB Environment\n",
        "print(\"🔑 Setting up Vector Database environment...\")\n",
        "\n",
        "# 🔧 CHANGE THESE VALUES to your actual Pinecone credentials\n",
        "PINECONE_API_KEY = 'your-pinecone-api-key-here'\n",
        "PINECONE_ENVIRONMENT = 'your-pinecone-environment-here'\n",
        "INDEX_NAME = 'sri-lankan-legal-docs'  # Your Pinecone index name\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "os.environ['PINECONE_ENVIRONMENT'] = PINECONE_ENVIRONMENT\n",
        "os.environ['INDEX_NAME'] = INDEX_NAME\n",
        "\n",
        "# Create .env file\n",
        "env_content = f\"\"\"PINECONE_API_KEY={PINECONE_API_KEY}\n",
        "PINECONE_ENVIRONMENT={PINECONE_ENVIRONMENT}\n",
        "INDEX_NAME={INDEX_NAME}\n",
        "\"\"\"\n",
        "\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"✅ Vector Database environment configured!\")\n",
        "print(f\"📊 Index Name: {INDEX_NAME}\")\n",
        "print(\"⚠️  Make sure to replace the placeholder API keys with your actual keys!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-legal-docs"
      },
      "outputs": [],
      "source": [
        "# 📚 Step 5: Check Legal Documents\n",
        "print(\"📚 Checking for legal documents...\")\n",
        "\n",
        "# Check for legal documents directory\n",
        "legal_docs_dir = 'legal_documents'\n",
        "if os.path.exists(legal_docs_dir):\n",
        "    print(f\"✅ Found legal documents directory: {legal_docs_dir}\")\n",
        "    \n",
        "    # List document types\n",
        "    for root, dirs, files in os.walk(legal_docs_dir):\n",
        "        if files:\n",
        "            rel_path = os.path.relpath(root, legal_docs_dir)\n",
        "            print(f\"📁 {rel_path}: {len(files)} files\")\n",
        "            # Show first few files as examples\n",
        "            for file in files[:3]:\n",
        "                print(f\"   📄 {file}\")\n",
        "            if len(files) > 3:\n",
        "                print(f\"   ... and {len(files) - 3} more files\")\n",
        "else:\n",
        "    print(\"❌ No legal_documents directory found!\")\n",
        "    print(\"💡 Please add your legal documents to the legal_documents folder\")\n",
        "    print(\"📁 Expected structure:\")\n",
        "    print(\"   legal_documents/\")\n",
        "    print(\"   ├── acts/\")\n",
        "    print(\"   ├── cases/\")\n",
        "    print(\"   └── regulations/\")\n",
        "\n",
        "print(\"\\n📊 System Information:\")\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits\n",
        "print(f\"💾 Available RAM: {!cat /proc/meminfo | grep MemAvailable}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-vector-processing"
      },
      "outputs": [],
      "source": [
        "# 🚀 Step 6: Initialize and Run Vector Database Processing\n",
        "print(\"🚀 Starting Vector Database processing...\")\n",
        "print(\"⏳ This may take several minutes depending on document size...\")\n",
        "\n",
        "try:\n",
        "    # Import and run the main vector DB processing\n",
        "    import subprocess\n",
        "    import sys\n",
        "    \n",
        "    # Run the main vector DB script\n",
        "    result = subprocess.run([sys.executable, 'main_fixed.py'], \n",
        "                          capture_output=True, text=True, timeout=3600)  # 1 hour timeout\n",
        "    \n",
        "    print(\"📤 Vector DB Processing Output:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(result.stdout)\n",
        "    \n",
        "    if result.stderr:\n",
        "        print(\"⚠️  Warnings/Errors:\")\n",
        "        print(result.stderr)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"\\n✅ Vector Database processing completed successfully!\")\n",
        "        print(\"🎉 Legal documents have been processed and stored in Pinecone!\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Processing failed with return code: {result.returncode}\")\n",
        "        \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"⏰ Processing timed out after 1 hour\")\n",
        "    print(\"💡 Try processing smaller batches of documents\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during processing: {e}\")\n",
        "    print(\"💡 Try running the processing manually in the next cell\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "manual-processing"
      },
      "outputs": [],
      "source": [
        "# 🔧 Step 7: Manual Processing (Alternative)\n",
        "print(\"🔧 Manual Vector DB Processing (if automatic failed)\")\n",
        "print(\"Uncomment and run the code below for manual processing:\")\n",
        "\n",
        "# Uncomment the following lines for manual processing:\n",
        "\n",
        "# try:\n",
        "#     # Import the main components\n",
        "#     from vector_db_connector import VectorDBConnector\n",
        "#     from document_processor import DocumentProcessor\n",
        "#     from embedding_generator import EmbeddingGenerator\n",
        "#     \n",
        "#     print(\"📊 Initializing Vector Database components...\")\n",
        "#     \n",
        "#     # Initialize components\n",
        "#     embedding_gen = EmbeddingGenerator()\n",
        "#     doc_processor = DocumentProcessor()\n",
        "#     vector_db = VectorDBConnector()\n",
        "#     \n",
        "#     print(\"📚 Processing legal documents...\")\n",
        "#     \n",
        "#     # Process documents\n",
        "#     processed_docs = doc_processor.process_directory('legal_documents')\n",
        "#     print(f\"✅ Processed {len(processed_docs)} documents\")\n",
        "#     \n",
        "#     # Generate embeddings and store\n",
        "#     for doc in processed_docs:\n",
        "#         embeddings = embedding_gen.generate_embeddings(doc['chunks'])\n",
        "#         vector_db.store_embeddings(doc['id'], embeddings, doc['metadata'])\n",
        "#     \n",
        "#     print(\"🎉 Manual processing completed successfully!\")\n",
        "#     \n",
        "# except Exception as e:\n",
        "#     print(f\"❌ Manual processing error: {e}\")\n",
        "#     import traceback\n",
        "#     traceback.print_exc()\n",
        "\n",
        "print(\"💡 To use manual processing:\")\n",
        "print(\"   1. Uncomment the code above\")\n",
        "print(\"   2. Run this cell\")\n",
        "print(\"   3. Monitor the output for any errors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify-database"
      },
      "outputs": [],
      "source": [
        "# 📊 Step 8: Verify Vector Database Status\n",
        "print(\"📊 Checking Vector Database status...\")\n",
        "\n",
        "try:\n",
        "    import pinecone\n",
        "    \n",
        "    # Initialize Pinecone\n",
        "    pinecone.init(\n",
        "        api_key=os.environ['PINECONE_API_KEY'],\n",
        "        environment=os.environ['PINECONE_ENVIRONMENT']\n",
        "    )\n",
        "    \n",
        "    # Check index status\n",
        "    index_name = os.environ['INDEX_NAME']\n",
        "    \n",
        "    if index_name in pinecone.list_indexes():\n",
        "        index = pinecone.Index(index_name)\n",
        "        stats = index.describe_index_stats()\n",
        "        \n",
        "        print(\"✅ Vector Database Status:\")\n",
        "        print(f\"📊 Index Name: {index_name}\")\n",
        "        print(f\"📈 Total Vectors: {stats['total_vector_count']}\")\n",
        "        print(f\"📏 Dimension: {stats['dimension']}\")\n",
        "        \n",
        "        if 'namespaces' in stats:\n",
        "            print(\"📁 Namespaces:\")\n",
        "            for namespace, info in stats['namespaces'].items():\n",
        "                print(f\"   {namespace}: {info['vector_count']} vectors\")\n",
        "        \n",
        "        print(\"\\n🎉 Vector Database is ready for RAG Module!\")\n",
        "        \n",
        "    else:\n",
        "        print(f\"❌ Index '{index_name}' not found!\")\n",
        "        print(\"Available indexes:\", pinecone.list_indexes())\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error checking database status: {e}\")\n",
        "    print(\"💡 Make sure your Pinecone credentials are correct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-vector-results"
      },
      "outputs": [],
      "source": [
        "# 💾 Step 9: Save Processing Results\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "print(\"💾 Saving Vector DB processing results...\")\n",
        "\n",
        "# Create results directory in Google Drive\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_dir = f'/content/drive/MyDrive/Vector_DB_Results_{timestamp}'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Save configuration and logs\n",
        "files_to_save = [\n",
        "    '.env',\n",
        "    'config.py',\n",
        "    'vector_db.log',\n",
        "    'processing.log',\n",
        "    'embeddings_stats.json'\n",
        "]\n",
        "\n",
        "for file_name in files_to_save:\n",
        "    if os.path.exists(file_name):\n",
        "        shutil.copy2(file_name, results_dir)\n",
        "        print(f\"✅ Saved {file_name}\")\n",
        "\n",
        "# Save processing summary\n",
        "summary = f\"\"\"Vector Database Processing Summary\n",
        "==========================================\n",
        "Timestamp: {datetime.now()}\n",
        "Index Name: {os.environ.get('INDEX_NAME', 'N/A')}\n",
        "Pinecone Environment: {os.environ.get('PINECONE_ENVIRONMENT', 'N/A')}\n",
        "\n",
        "Processing completed in Google Colab\n",
        "Ready for RAG Module integration\n",
        "\"\"\"\n",
        "\n",
        "with open(f'{results_dir}/processing_summary.txt', 'w') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "print(f\"\\n💾 Results saved to: {results_dir}\")\n",
        "print(\"✅ Vector Database processing backup completed!\")\n",
        "print(\"\\n🔗 Next Steps:\")\n",
        "print(\"   1. Use the RAG Module Colab notebook\")\n",
        "print(\"   2. Configure it with the same Pinecone credentials\")\n",
        "print(\"   3. Start asking legal questions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "completion-summary"
      },
      "source": [
        "## 🎯 Vector Database Module Complete!\n",
        "\n",
        "### ✅ What was accomplished:\n",
        "- Legal documents processed and chunked\n",
        "- Embeddings generated using Legal-BERT/Sentence-BERT\n",
        "- Documents stored in Pinecone vector database\n",
        "- Multilingual support enabled\n",
        "- Proper sequence numbers and metadata added\n",
        "\n",
        "### 🔗 Next Steps:\n",
        "1. **Use the RAG Module Colab notebook** to create the question-answering interface\n",
        "2. **Configure the same Pinecone credentials** in the RAG module\n",
        "3. **Start asking legal questions** and get AI-powered responses!\n",
        "\n",
        "### 📊 Database Ready For:\n",
        "- ✅ Legal question answering\n",
        "- ✅ Semantic search\n",
        "- ✅ Document retrieval\n",
        "- ✅ Multi-language queries\n",
        "- ✅ Context-aware responses\n",
        "\n",
        "Your Vector Database is now ready to power the RAG Module! 🚀\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
